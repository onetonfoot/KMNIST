{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.models import resnet18\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Need to add classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import loaders \n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from generator import Generator, fonts\n",
    "import string\n",
    "from augmentation import aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 50\n",
    "transforms = T.Compose([\n",
    "#     Rearrange(\"h w -> () h w\"),\n",
    "    #TODO Normalize with dataset mean and std...\n",
    "    T.Resize((64,64)),\n",
    "    T.ToTensor(),\n",
    "#     T.Lambda(lambda x: (x < threshold).float().mean(0, keepdim=True))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = string.ascii_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = Generator(chars, fonts, aug)\n",
    "test_gen = Generator(chars, fonts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = loaders.FontDs(train_gen, 60000, transforms)\n",
    "test_ds =  loaders.FontDs(test_gen, 10000, transforms)\n",
    "\n",
    "# train_ds = loaders.KMNIST10(\"data/10\", tfms=transforms)\n",
    "# test_ds = loaders.KMNIST10(\"data/10\", train=False, tfms=transforms)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=32, num_workers=8)\n",
    "test_dl = DataLoader(test_ds, batch_size=32, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "vector_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(3, vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss and Optim\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://omoindrot.github.io/triplet-loss#a-better-implementation-with-online-triplet-mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss import batch_all_triplet_loss, batch_hard_triplet_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.optim import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "opt = SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import FileWriter, SummaryWriter \n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_frac = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = Path(\"checkpoints/siamese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = batch_all_triplet_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86c955423acb421bb8fe7e1cd2c4b5aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1875), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "788e9fc9cb204dd88d277cea75f95de0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=313), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "664caf5cf72646a98172719d426088c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1875), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for _ in range(20):\n",
    "    epoch += 1\n",
    "    \n",
    "    #Training\n",
    "    train_loss = 0\n",
    "    train_frac = 0\n",
    "    pbar = tqdm(train_dl)\n",
    "\n",
    "    for data in pbar:\n",
    "        opt.zero_grad()\n",
    "        x, y = [i.to(device) for i in data]\n",
    "        embeddings = model(x)\n",
    "        loss, frac = loss_fn(y, embeddings)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        train_loss += loss.item()\n",
    "        train_frac += frac.item()\n",
    "\n",
    "    train_loss /= len(train_ds)\n",
    "    train_frac /= len(train_dl)\n",
    "    pbar.set_description(f\"Training {epoch} | Loss: {train_loss:.3f} | Fraction {train_frac:.3f}\")\n",
    "\n",
    "    # Testing\n",
    "    test_loss = 0\n",
    "    test_frac = 0\n",
    "    pbar = tqdm(test_dl)\n",
    "    \n",
    "    test_embeddings = []\n",
    "    test_imgs = []\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in pbar:\n",
    "            x, y = [i.to(device) for i in data]\n",
    "            embeddings = model(x)\n",
    "            loss, frac = loss_fn(y, embeddings)\n",
    "            test_loss += loss.item()\n",
    "            test_frac += frac.item()\n",
    "            test_embeddings.append(embeddings.cpu())\n",
    "            test_imgs.append(x.cpu())\n",
    "            \n",
    "    \n",
    "    test_embeddings = torch.cat(test_embeddings, 0)\n",
    "    test_imgs = torch.cat(test_imgs, 0)\n",
    "    summary.add_embedding(test_embeddings, global_step=epoch, label_img=test_imgs, tag=\"embeddings\")\n",
    "    test_loss /= len(test_ds)\n",
    "    test_frac /= len(test_dl)\n",
    "    pbar.set_description(f\"Testing {epoch} | Loss: {test_loss:.3f} | Fraction {test_frac:.3f}\")\n",
    "    \n",
    "    \n",
    "    # Tensorboard\n",
    "    summary.add_scalars(\"siamese_loss\", {\n",
    "        \"train\" : train_loss,\n",
    "        \"test\" : test_loss,\n",
    "    }, epoch)\n",
    "    \n",
    "    summary.add_scalars(\"fraction\", {\n",
    "        \"train\" : train_frac,\n",
    "        \"test\" :  test_frac,\n",
    "    }, epoch)\n",
    "   \n",
    "\n",
    "    summary.file_writer.flush()\n",
    "    \n",
    "    #Saving the model\n",
    "    if test_frac < best_frac:\n",
    "        best_frac = test_frac\n",
    "        checkpoints.mkdir(parents=True, exist_ok=True)\n",
    "        torch.save(model.state_dict(), checkpoints / \"best_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"checkpoints/model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       172\n",
      "           1       1.00      1.00      1.00       186\n",
      "           2       1.00      1.00      1.00       179\n",
      "           3       0.97      1.00      0.98       185\n",
      "           4       1.00      1.00      1.00       191\n",
      "           5       1.00      0.99      0.99       190\n",
      "           6       1.00      0.99      1.00       198\n",
      "           7       0.95      1.00      0.97       212\n",
      "           8       0.97      0.99      0.98       200\n",
      "           9       0.79      0.98      0.87       198\n",
      "          10       1.00      1.00      1.00       202\n",
      "          11       0.71      0.73      0.72       195\n",
      "          12       1.00      0.95      0.97       215\n",
      "          13       0.99      1.00      0.99       184\n",
      "          14       1.00      1.00      1.00       185\n",
      "          15       1.00      0.98      0.99       167\n",
      "          16       0.94      0.99      0.97       189\n",
      "          17       1.00      1.00      1.00       213\n",
      "          18       1.00      1.00      1.00       190\n",
      "          19       0.99      1.00      1.00       199\n",
      "          20       1.00      1.00      1.00       201\n",
      "          21       1.00      1.00      1.00       203\n",
      "          22       0.95      0.99      0.97       208\n",
      "          23       1.00      1.00      1.00       172\n",
      "          24       1.00      1.00      1.00       199\n",
      "          25       1.00      1.00      1.00       174\n",
      "          26       1.00      1.00      1.00       181\n",
      "          27       0.98      1.00      0.99       177\n",
      "          28       1.00      1.00      1.00       205\n",
      "          29       0.99      0.99      0.99       175\n",
      "          30       0.96      0.97      0.97       197\n",
      "          31       0.98      1.00      0.99       209\n",
      "          32       0.99      0.92      0.96       192\n",
      "          33       1.00      0.94      0.97       192\n",
      "          34       0.74      0.69      0.71       204\n",
      "          35       0.98      0.75      0.85       210\n",
      "          36       1.00      1.00      1.00       202\n",
      "          37       1.00      1.00      1.00       184\n",
      "          38       1.00      0.90      0.95       184\n",
      "          39       0.93      1.00      0.96       168\n",
      "          40       1.00      0.93      0.96       205\n",
      "          41       1.00      1.00      1.00       182\n",
      "          42       1.00      0.94      0.97       186\n",
      "          43       0.98      1.00      0.99       214\n",
      "          44       0.98      1.00      0.99       176\n",
      "          45       0.97      0.99      0.98       173\n",
      "          46       0.96      1.00      0.98       230\n",
      "          47       1.00      1.00      1.00       202\n",
      "          48       0.98      1.00      0.99       199\n",
      "          49       1.00      1.00      1.00       173\n",
      "          50       1.00      1.00      1.00       175\n",
      "          51       1.00      1.00      1.00       198\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ans, preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
